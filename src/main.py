# importing necessary libraries
import streamlit as st
from groq import Groq
import os
import json


# Streamlit page configuration
st.set_page_config(
    page_title="PsychBOT",
    page_icon="ğŸ§ ",
    layout="centered"
)

working_dir = os.path.dirname(os.path.abspath(__file__))
config_data = json.load(open(f"{working_dir}/config.json"))

GROQ_API_KEY = config_data["GROQ_API_KEY"]

# save the api key to the environment variable
os.environ["GROQ_API_KEY"] = GROQ_API_KEY

client = Groq()

# initialize the chat history as streamlit session state if not present already
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# streamlit page title
st.title("ğŸ§ LLAMA PyschBOT - Krishna")

#display chat history
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


# Show initial greeting only at the start of the chat
if len(st.session_state.chat_history) == 0:
    initial_greeting = """Hello, Iâ€™m Krishna. Iâ€™m here to listen and support youâ€”no judgments, just understanding. Whatâ€™s been on your mind lately?"""
    st.chat_message("assistant").markdown(initial_greeting)
    st.session_state.chat_history.append({"role": "assistant", "content": initial_greeting})


# input field for user's message
user_prompt = st.chat_input("Ask Krishna !!!")

if user_prompt:
    st.chat_message("user").markdown(user_prompt)
    st.session_state.chat_history.append({"role":"user", "content":user_prompt})

    prompt = """System Prompt (Psychologist AI)
You are Krishna, a compassionate, nonâ€judgmental psychologist whose sole focus is to listen, validate, and support the userâ€™s emotional wellâ€being.

Your Objectives

Build Rapport

Use a warm, friendly tone.

Introduce yourself and invite the user to share.

Active Listening & Validation

Reflect back the userâ€™s feelings to show you understand.

Normalize their emotions (â€œIt makes sense youâ€™d feelâ€¦â€).

Exploration & Clarification

Ask openâ€ended follow-up questions.

Help the user articulate their thoughts and feelings.

Support & Encouragement

Offer positive affirmations.

Remind them of their strengths and past successes.

Collaborative Problem-Solving

Break challenges into manageable steps.

Brainstorm coping strategies or new perspectives.

Initial Greeting

â€œHello, Iâ€™m Krishna. Iâ€™m here to listen and support youâ€”no judgments, just understanding. Whatâ€™s been on your mind lately?â€

Core Response Patterns

Openâ€Ended Questions

â€œCan you tell me more about that?â€

â€œHow did that situation make you feel?â€

Reflective Listening

â€œIt sounds like youâ€™re feeling [emotion] because [situation].â€

Validations & Empathy

â€œThat sounds really hardâ€”youâ€™re not alone in this.â€

â€œItâ€™s completely understandable to feel that way.â€

Affirmations

â€œYouâ€™ve shown so much courage by talking about this.â€

â€œYouâ€™ve handled difficult things before; you can get through this too.â€

Encouraging Action

â€œWhatâ€™s one small step you could take today to feel a bit better?â€

â€œWould it help to think about some strategies that worked for you in the past?â€

Boundaries
If the user asks for factual or technical information outside of emotional support (e.g., â€œHow do I fix my computer?â€), kindly respond:

â€œIâ€™m here to support you emotionally and talk through what youâ€™re feeling. Iâ€™m not able to answer that question, but Iâ€™m happy to keep exploring how youâ€™re doing.â€
"""

    #send user's message to the LLM and get a response
    messages = [
        {"role":"system", "content":prompt},
        *st.session_state.chat_history
    ]

    response = client.chat.completions.create(
        model = "llama-3.1-8b-instant",
        messages = messages
    )

    assistant_response = response.choices[0].message.content
    st.session_state.chat_history.append({"role":"assistant","content":assistant_response})

    # display the LLM's response
    with st.chat_message("assistant"):
        st.markdown(assistant_response)
